[33m976a903[m[33m ([m[1;36mHEAD -> [m[1;32mmaster[m[33m, [m[1;31morigin/master[m[33m, [m[1;31morigin/HEAD[m[33m)[m Merge pull request #294 from gentlelinuxer/fix-mnist
[33m08f6dd5[m PR test
[33m92df8fc[m Merge pull request #263 from gentlelinuxer/test
[33mf1a28b1[m PR test
[33m943af71[m Merge pull request #136 from gentlelinuxer/master
[33m8e1edd9[m PR test
[33m4c0d68c[m Merge pull request #128 from gentlelinuxer/master
[33m5f6d671[m PR test
[33mf070092[m Merge pull request #121 from gentlelinuxer/master
[33me27bf6b[m Add hello2.txt
[33m4c55768[m Merge pull request #107 from gentlelinuxer/master
[33m4117f0f[m PR test
[33mecff462[m Merge pull request #91 from gentlelinuxer/master
[33m5c89401[m PR test
[33m717aabb[m Merge pull request #71 from gentlelinuxer/master
[33m8143431[m PR test
[33m33af28c[m Revert "Remove unused argument for test method. (#746)"
[33mddc2d56[m Revert "added missing non-linearity"
[33m2e43ba9[m Revert "Correct typo in default value within help (#667)"
[33me7870c1[m remove tput, causes errors in CI
[33m6c8e2ba[m fix warnings and failures
[33m3c032e8[m Add CI to run examples via github action
[33m19ae7a3[m Merge pull request #792 from mrshenli/batch
[33m9ec78d1[m Merge pull request #796 from mrshenli/pileline
[33m6cf0bdf[m Update pipeline parallel example to use RRef helpers
[33m49ec0bd[m tweak running examples without cuda (#794)
[33mda85831[m Adding Batch RPC example
[33m59caa16[m Merge pull request #791 from seemethere/fix_transformer
[33m13acec6[m word_language_model: Fix Transformer init_weights
[33medfa9f2[m Fix errors executing run_python_examples.sh "install_deps,run_all" (#787)
[33m7016919[m Update word-level LM arguments in README (#786)
[33m59423c5[m Delete unnecessary blank lines (#785)
[33ma4b0aba[m fix the issue PR #799 left (#781)
[33m984700d[m Fix grad in-place operation (#779)
[33md91adc9[m Fix parameter server command line options in README (#776)
[33m4e9172b[m Fix initialization of weight of Decoder (#775)
[33m22ee056[m Fix cpp/mnist CMakeList build. (#764)
[33m1877b87[m Eliminate .data access for parameters as much as possible (#767)
[33m31643b2[m Fix Parameter Server Example (#774)
[33me9b2f8e[m correcting the pipeline rpc example (#773)
[33m8dcb9c7[m Merge pull request #743 from drdarshan/master
[33ma5fdab9[m Merge branch 'master' into master
[33mb9f3b2e[m Update dcgan.cpp (#765)
[33me49fa58[m Merge pull request #763 from mrshenli/ddp
[33m0cbd699[m Adding DDP example
[33m69d2798[m Revert "loss detach (#731)" (#758)
[33md431037[m Adding a distributed pipeline parallelism example for RPC (#749)
[33m391be73[m loss detach (#731)
[33m80fcb66[m Remove unused argument for test method. (#746)
[33m496d3b9[m update (#748)
[33mad775ac[m C++ autograd example (#745)
[33m39ff9d8[m Delete ProcessMapping.svg
[33ma5cafe9[m Replace SVG image with GitHub Permalink
[33m6a64766[m Remove explicit setting of random seed
[33me838b9d[m Address PR comments in README
[33ma9ca8ff[m Remove math notation from README, replace with italics
[33m45b6110[m Remove scaling of image
[33md7f66aa[m Add files via upload
[33m6f632ef[m Create example.py
[33m00aeea1[m Create README.md
[33m234bcff[m Merge pull request #733 from osalpekar/dist_autograd_update
[33m8a5b379[m Merge pull request #705 from rohan-varma/add_param_server
[33m6d29c3b[m update
[33ma0da8d4[m update
[33m23695e8[m update
[33m2da3f63[m update
[33ma47667c[m Use f-strings
[33m22cda00[m UPdate
[33m9f50c64[m Move tensors in and out of GPU
[33m81790c6[m Update
[33m4902431[m fix loss calculation for RNN (#732)
[33m55506b5[m updated dist_autograd and dist_optim to be functional per API change
[33m5551061[m more complete description for ArgumentParser (#670)
[33m355ffd0[m change regression/poly_desc() (#684)
[33m1318058[m Fix typo in comment (#690)
[33m7f8b329[m dcgan: using `fake` dataset still requires dataroot parameter (#699)
[33m02d5761[m typo in comment (#701)
[33m3074510[m fix missing/extra spaces (#703)
[33md74f57c[m Add help message for snli example (#707)
[33m2b2c40b[m Update .gitignore (#709)
[33m6f38987[m Update README.md for Argument (#711)
[33mdb0dbf6[m README.md : Add descriptions for optional arguments (#712)
[33mdce9319[m added missing non-linearity
[33m47f09db[m Fix shebang (#686)
[33m1800513[m Remove for double usage of log_softmax (#721)
[33m9838fbc[m update
[33m1cabfdb[m Added support for using 2 GPUs
[33mbfc5b5d[m Still need to take in CUDA device programatically
[33m14deff8[m Added instructions
[33md2f6682[m Format
[33m788bc79[m Address comments and train on GPU
[33m01d70cd[m Make multi-host setup possible
[33me9e7672[m clarify imagenet download
[33m063aac7[m Updat
[33mfb6829c[m Added data and loss to show actual training
[33m7ce9e92[m Update
[33m53a0731[m WIP: parameter server example
[33m0c1654d[m Update C++ frontend examples for v1.4.0 (#697)
[33mec10eee[m Adding an RPC tutorial using a simple reinforcement learning application (#688)
[33mf692b1f[m Adding Distributed Model Parallel Training Example for RNN (#662)
[33m2796747[m update CXX compiler from 11 to 14 (#678)
[33m7d75f8a[m fix: Namespace issue of Reduction in CPP MNIST (#673)
[33m6c51ca5[m Correct typo in default value within help (#667)
[33m0634306[m Improving mnist example model (#658)
[33m60108ed[m Fix formatting to comply with PEP8 (#654)
[33m4e00723[m Prefixed `at::` wherever `Reduction::` is used (#644)
[33mee964a2[m Fix load model when a single GPU is used (#629)
[33m632d385[m Update model.py (#625)
[33m7a86e71[m Added Transfer Learning using Libtorch and OpenCV (#626)
[33m5c5ae99[m Merge pull request #627 from peterjc123/win_fix
[33mef196d8[m Add copy logic for Windows
[33md3120cd[m Reflecting the change in VAE paper name (#616)
[33m90738a7[m Fix error AttributeError: 'RNNModel' object has no attribute 'model_type' (#614)
[33m6f62fcd[m Clean readme (#610)
[33m1b1a974[m Removing unused variable (#612)
[33m4581968[m Apply Transformer model for the word language problem in pytorch/examples (#555)
[33md587b53[m Fix epoch data type in cpp mnist example (#601)
[33m99a83a2[m C++ custom dataset (#583)
[33mace46c8[m Update README.md for Arguments (#596)
[33m013f957[m Added instructive comments (#589)
[33m79d71b8[m add a script to run all pytorch examples (#591)
[33m71a9207[m Added regression example (#587)
[33mf16467a[m Divide Up args.workers by ngpus_per_node (#585)
[33m1de2ff9[m Fix ProgressMeter usage in imagenet validation (#577)
[33m2ea9f6a[m Fix Python 2 compatibility (#575)
[33m97304e2[m enhancing readability (#495)
[33mfa3f739[m Consider PyTorch 1.1 for _download_url_to_file module path (#565)
[33m5b1f450[m Consistent learning rate for ResNet in readme (#556)
[33m5df464c[m fix log cannot be printed right (#541)
[33mb142c4b[m Remove duplicated argument (#535)
[33m27a6244[m Refactor print progress of ImageNet training (#529)
[33m3b349ad[m [C++][DCGAN] Increment batch_index before the if statements? (#523)
[33m67e5b06[m Update main.py (#520)
[33m87d9a1e[m Add dropout layer in reinforce (#509)
[33m447974f[m Fixes bug when loading checkpoint of different GPU (#515)
[33mb232bf3[m Tidy var names for RL examples (#513)
[33mea825a5[m Add Cuda support to mnist_hogwild (#508)
[33mfe8abc3[m Remove deprecated & unused Variable() (#496)
[33m0d3fe14[m Use argmax() instead of max()[1] in mnist/main.py (#494)
[33m29a38c6[m Add cpp folder for C++ frontend examples (#492)
[33m5d27fdb[m Update README.md (#493)
[33m635e64c[m Add missing rank argument (#490)
[33me0929a4[m remove more spurious perplexity references
[33m97e3e13[m remove references to PTB perplexity numbers
[33mc5985a8[m Divide args.workers by ngpus_per_node (#485)
[33m44053c5[m Add missing world size argument (#484)
[33md6b5211[m delete .swp file. (#474)
[33md8dd8ca[m Mnist update (#469)
[33m35a9d84[m fix a typo (#466)
[33m64f829c[m Examples dcgan (#464)
[33m6d08877[m python 2 fix
[33m15e2771[m ImageNet, distributed bug fixes (#462)
[33m91f230a[m Fix missing required argument for --evaluate. (#455)
[33m12e4340[m Fix name of dataset (#451)
[33mdf70aa7[m fix broken args\n\nFor multiple long options python takes the first as attribute name by default. The latest commit swapped the order of options that causes the script an error. Added dest option to explicitly specify the valid attribute name (#454)
[33m537f697[m Unified order of flag names in argparser: short flag names ('-f') go before long flag names ('--foo'). (#449)
[33m0fadadc[m [Distributed] Multiprocessing Distributed Training for ImageNet Example (#441)
[33m81f47e8[m Bug fix in the calculation of the validation loss (#427)
[33m05ed879[m modified the hogwild example to perform testing outside the different training processes (#426)
[33m502e45d[m replace Upsample layer with interpolate function (#424)
[33m323079f[m Use torchtext 0.3.1 (#423)
[33m0c1fcc8[m Update all prec occurrences to acc (#420)
[33m95d5fdd[m Fix bug in reparameterize() (#419)
[33me128eda[m Add tokenization (#417)
[33m8473762[m precision -> accuracy
[33m753d086[m removed two deprecated function calls, added __name__ check to address multithreading bug in dataloader (#414)
[33m6fd43cd[m Updated clipping to torch.nn.utils.clip_grad_norm_ (#403)
[33m2fc0211[m fix fast_neural_style --export_onnx (#397)
[33m75e7c75[m Fix snli device to work with newest torchtext (#394)
[33mb5f3612[m fix fast neural transfer on cuda (#392)
[33m98b1fce[m Add support for deteriminstic behavior in ImageNet benchmark. (#381)
[33m29c2ed8[m Make the data preparation process cross-platform (#379)
[33mf835081[m open file explicitely using utf-8 (#366)
[33mf982047[m Convert to proper script with main(), fix #352 (#353)
[33m9dc6538[m fix 0.4 version compliance (#354)
[33meee5ca3[m Export Word Language Model to ONNX (#348)
[33m0604520[m Onnx export (#322)
[33m83f1b5c[m Fix call to Tensor.cuda()
[33mc7df3c0[m VAE: use `F.sigmoid` as it is parameter-free (#338)
[33m56114a6[m Update main.py
[33md7e452e[m Update main.py (#337)
[33m645c7c3[m codemod for 0.4 (#331) (#336)
[33mdcdabc2[m Fix arg of LSUN: db_path -> root (#319)
[33mc66593f[m fix accuracy bug
[33m4ef2d4d[m Fix actor_critic example (#301)
[33m963f7d1[m Fix VAE losses (sum over everything) (#296)
[33m8256aee[m Fix UserWarning in two examples (#293)
[33me11e079[m Fix indentation to be self-consistent (#279)
[33me23a9b4[m fix: `Multinomial` is now `Categorical`
[33md5678bc[m Replace WikiText-2 files with correct dataset (#264)
[33mca90734[m Fix bugs and improve performance
[33m82cef44[m Fix action indexing
[33m9faf2c6[m Update RL examples to use torch.distributions instead of reinforce
[33me0d33a6[m Scale -> Resize + RandomSizedCrop -> RandomResizedCrop
[33mcf74c81[m Swap PTB for Wikitext-2 (which is open access)
[33m62d5ca5[m Add linear layer to time series prediction
[33mfad7759[m Consistent newlines
[33m7532a61[m Document the data arrangement in word_language_model
[33m23f8abf[m bug fix: vocab.load_vectors signature update
[33m9a02f2a[m Fix an argument instruction in mnist_hogwild
[33m7d0d413[m Add link to script for preparing imagenet val data
[33maa7adf0[m Remove unused math import
[33m9fe431e[m Fix VAE loss + improve reconstruction viz
[33m5f24730[m Add support for CUDA
[33mab7cb38[m Balance VAE losses, add reconstruction + sampling
[33mddf9e30[m h rather than c should be fed into the next layer of LSTM (#222)
[33m3648cbc[m vae: Fix `UserWarning` (#220)
[33m30b9c0e[m Update README.md (#219)
[33ma723598[m change lr to 0.8 to fix the issue for 0.2
[33m407bd3e[m minor spelling, evaluted->evaluated
[33m930ae27[m Change test DataLoader to use the test batch size
[33m2dca104[m reinforcement_learning fix reward threshold
[33m86bc3e5[m Add model_names back. Fixes #195
[33mfb9ca4d[m mnist 0.2 fixes
[33m9053040[m fix for 0.2
[33m9012fae[m fix for 0.2
[33m5c2b513[m Change "gain" -> "calculate_gain" (#192)
[33mb0a116e[m Add an option to perform distributed ImageNet training (#185)
[33m0722b2f[m Remove unused imports in SR example (#190)
[33md165984[m Use nn.init from core to init SR example (#189)
[33m6b17f79[m README: Correct case and add link to PyTorch (#188)
[33ma4e6972[m Fix test data in time_sequence_prediction (#186)
[33m10b22dc[m Fix test_epoch typo (#183)
[33m08be28e[m This PR fixes error raised during element-wise variable division. (#182)
[33m2d0f1c4[m added a function makedirs() which works both for python 2 and 3 (#176)
[33m1b26501[m fix bugs in generalization error calculation (#179)
[33mcab5705[m Bugs In MNIST (#175)
[33md6e6324[m added comments in snli/train.py, no code changes (#177)
[33m53f25e0[m unuse average over batch
[33md610b4a[m remove useless line
[33m3b60784[m add comments
[33m3aca2d7[m fix test() param, and fix bugs in nll_loss
[33m300ae6b[m parameter in test() function is useless
[33m1c6d9d2[m Change reusing of Variables (#150)
[33mdc10cd8[m fast-neural-style example (#129)
[33m5c41070[m mnist_hogwild manual breaking of gradient sharing removed (#138)
[33m89facbe[m replace model by policy (#154)
[33m140a8bf[m Fix help message for no-cuda (#153)
[33m2f7b7ad[m snli/model.py: can run using Python 2.* (#145)
[33m0984955[m save/load optimizer state (#141)
[33m3f21078[m Changes in `reinforce.py` (#140)
[33m28471f2[m Fix typo in imagenet/main.py (#135)
[33m50afe29[m open without 'rb' caused Python 3 to open this in text mode and fail (#133)
[33m046abef[m Update README.md
[33m7c57e52[m Add a time sequence prediction example (#118)
[33mac5b745[m fix dcgan
[33mf89a371[m fix a bug in DCGAN (#121)
[33m0bdcb42[m Fix highlighted headers in readme (#122)
[33mf2a771a[m Handle tied + dimensions mismatch (#124)
[33m18df41e[m fix direct access to subsections
[33mc4b48c4[m lr floating division
[33m75e435f[m apply normalization for output image of dcgan generator (#127)
[33m91c4f3e[m update formatting in README
[33meee4bb8[m some wrong typing (#125)
[33mf931931[m Remove rectifier before softmax (#117)
[33me2f885d[m remove OpenNMT and link to elsewhere
[33m63e06c2[m move OpenNMT
[33ma60bd4e[m Fix random seeding in DCGAN (#108)
[33mb8cacb0[m Switch the model to evaluation mode before generation
[33m42e5b99[m Simple typo fix to the download script
[33mbde9f82[m one more lowercase in dict
[33mfcaf4c2[m backwards compatibility for checkpoints
[33m94ebdc8[m Grouping bash commands together
[33m988ee51[m state_dicts for translation and optimizer
[33m4af62f9[m saving with state_dict
[33mf23ed44[m removing unused variables
[33m8bb7c5a[m off by one in printing batch number
[33m0e77a0b[m accuracy now an average over log_interval batches
[33m39bb701[m curriculum off by one
[33m4214691[m batch printing was off
[33m1200378[m num_batches was off by one
[33m7ececef[m allowing validation data to volatile
[33m1649caf[m touch ups and README updates
[33m99231ac[m adding word level accuracy as a metric
[33mfd87818[m adding option to shuffle mini-batches
[33m8ea8929[m allowing learning rate update for non-sgd optimizers
[33m9913e4c[m manual unrolling was broken for brnn; patch until varlen rnn replacement
[33m1100ff5[m allows use of models trained on dataset to be trained on another; doesn't augment vocab
[33md1a14ed[m mend
[33m0c634a1[m new DataParallel allows dim 1; remove unnecessary transposes; add train_ppl to chkpt
[33mc90842c[m reverting cudnn decoder to lstmcell
[33mbf82a7b[m cudnn decoder
[33m4a11dd7[m spacing in readme
[33me803cb2[m clean up the readme
[33m7946cf2[m cleaning up readme
[33mb0dad45[m tips for non-demo mt via flickr30k example
[33mdb92469[m preprocess needs to use lower option
[33m60960c6[m adding files to ignore
[33m1b84cff[m pointing out one way to do bleu scores in README
[33mdcbe205[m allowing lowercase option
[33me426bce[m removing unnecessary def
[33m65831db[m Variables in Translator can be volatile
[33m720f292[m bug in total num predicted words
[33mac610f8[m index in verbose translate was fixed
[33mb9235a7[m adding src/tgt tokens/s
[33mf5f63fb[m nn.clip_grad_norm
[33m55c92a8[m decoder hidden state fix
[33mcc0ea01[m default type for start_decay_at
[33mcae6d71[m using ModuleList
[33m90fa16a[m replacing opt.cuda with opt.gpus as needed
[33m4d137ed[m using split instead of chunk
[33ma81593a[m removing reinit of checkpoint params again
[33mfa70523[m README changes for multi-gpu
[33m59f3bb0[m translate bug fix
[33maecda28[m update attribution of weight tying in word_language_model (#109)
[33mbcea1f5[m PTB LM example now has far better perplexity for both large (72.30) and small (87.17) models
[33m36b14bb[m Change the calculation method of the match number. Since if dataset number is smaller than 64, it will be 0.
[33m0598cff[m fixes for master
[33me83370b[m fix for master
[33m0940311[m Replace clip_gradient with torch's newly included clip_grad_norm (fixes #95)
[33m179fb76[m Fix typo in logging of ImageNet model loading
[33m130afec[m Revert "add flush to print" (#92)
[33mc39a889[m add lmdb to requirements of dcgan. Add instructions to download LSUN to dcgan/README
[33me8d5bbd[m Command Line Interface backwards compatible fix for models.py (#85)
[33m409a726[m add flush to print (#81)
[33m1c16b6c[m remove unused lines (#84)
[33mb840cad[m update translate.py gpu option
[33ma742fe2[m friendlier gpu options in translate
[33m1d0d15d[m should not re-init params on load from chkpt
[33mfcc2ab1[m altering translate to be compatible with nn.DataParallel
[33m0dee89a[m allowing the option of single device
[33mf485f7b[m multi-gpu via DataParallel
[33mc84f7df[m [onmt] Update README with models; move data to AWS
[33m6be19f9[m fixed divide by zero error
[33mf3a883c[m start_epoch should increment from saved epoch
[33mfa7e589[m moving param init
[33mebd985d[m params should not be reinitialized for loaded models
[33mfc52742[m final cleanup
[33m301b0cb[m train from checkpoint
[33mb95b4c3[m Remove language features leftovers
[33md88d377[m cleanup train.py
[33m9b33dcf[m OpenNMT example now updated and training
[33m7b2dd86[m add data text files
[33m741e260[m Initial checkin
[33m2ff9485[m Add instruction to use specified GPU id (#73)
[33m190f8fa[m Prevent 2 forward passes with detach
[33mec4802c[m Update main.py (#68)
[33mf6770fa[m removing default snapshot and setting cuda to avoid pytroch issue 689
[33m9108041[m updates for torchtext and loading from snapshot
[33m832141b[m Update main.py (#65)
[33mb59153a[m Create LICENSE
[33m2cfe5e1[m Remove module names from arch list in Imagenet example (#62)
[33m9f125c1[m Merge pull request #61 from tomsercu/master
[33m3243317[m D( G(z).detach() ), added D means for monitoring
[33mc66216f[m Merge pull request #57 from bmccann/snli_glove_vectors
[33m181ac16[m fix argparse type of gamma
[33md10a529[m remove fictitious play stuff from example that was accidentally committed
[33mdb83349[m updating glove vector interface with torchtext
[33me2b9063[m fixing bug in bidirectional and setting to default
[33m5f8d3ca[m simpler vector loading and defaults
[33m57b48f3[m defaulting unidirectional
[33m67780a6[m adding some to the READMEs
[33ma7a5cdc[m adding projection layer
[33m88508c0[m lowercasing and caching
[33m92d566a[m adding glove vectors
[33m623cd7f[m adding some options
[33m10cc0b7[m snli example; no glove
[33mc6bff8c[m default number of training epoch should be 10 in the description
[33m8cfb021[m Merge pull request #52 from pytorch/vae_fix
[33m48a4b51[m Fix CUDA mode in VAE example
[33m8ecce20[m Merge pull request #48 from pytorch/regression
[33m8f4a461[m Fix regression example
[33m58591e2[m Actor was not being used in actor-critic
[33m363a947[m fix requirements
[33me749ed0[m Merge pull request #44 from smartkiwi/master
[33mae40df7[m just remove the call
[33m56d7bb8[m missing import
[33m2573465[m Make example python 2.7 compatible
[33m7f612f9[m Merge pull request #42 from ebetica/reinforce
[33m4b5bd87[m Adds naive REINFORCE algorithm
[33m76463bc[m Merge pull request #41 from lukeyeager/logreg-fix
[33mcad2233[m Fix logistic regression example
[33m182f862[m Merge pull request #40 from lukeyeager/logreg
[33me84fdf9[m Update README.md (#39)
[33m238a0db[m Add logistic regression example
[33mb4b6ba4[m Merge pull request #38 from andreaskoepf/patch-1
[33m2c7b523[m Add arXiv link to VAE paper
[33mf39536f[m removing OpenNMT
[33m4dece01[m Merge pull request #34 from ebetica/fix1
[33m3dc0077[m Bigger network converges in 160 steps
[33m2bc4454[m Merge pull request #33 from pytorch/rnn
[33md5a75ba[m Refactor language modeling example
[33m8c5008e[m Merge pull request #32 from Kaixhin/master
[33mda293af[m Rename REINFORCE to actor-critic
[33mb59700c[m Update README.md
[33mb85fcbd[m Merge pull request #31 from pytorch/reinforce
[33md82a1df[m Update README.md
[33mc053f31[m Fix dropout flag
[33m4a98422[m Add REINFORCE example
[33m6625bcd[m Update README.md
[33mc94694b[m Add hogwild example
[33m32c7386[m Improve MNIST example
[33m1d84800[m VAE -> vae
[33m8348a61[m Update README.md
[33m152f44d[m Merge pull request #25 from adamlerer/onmt
[33mdc5926a[m Merge branch 'master' into onmt
[33m1a9d6b5[m Container -> Module
[33m7d70448[m Merge pull request #29 from pytorch/grad_fix
[33me6aecf5[m Fix for changed .grad type
[33m0435cb1[m Merge pull request #28 from Maratyszcza/master
[33m9a92d76[m Auto-detect architectures in ImageNet example
[33m66238bc[m Update README.md
[33m8952bff[m Merge pull request #27 from alykhantejani/super_resolution_example
[33m6238eb6[m Add super resolution example
[33m8254bd4[m random stuff
[33m7ee5c4c[m multi-layer decoder
[33m62555a6[m memory efficient decoding
[33mc048078[m memory efficient decoding
[33mc9993fe[m Used models from torchvision (#26)
[33mff01095[m feed encoder hidden states to decoder; and other debugging
[33m50da9ac[m Update README.md
[33mc2c4f5f[m delete lots of unnecessary files
[33m2572f11[m add bidirectional, fix bugs, add options
[33md4a27ca[m Merge pull request #23 from colesbury/alexnet
[33m0b54188[m Add AlexNet model definition
[33mc9e2072[m fixes
[33mb71427e[m Update README.md
[33m8a70c27[m Trains for multiple epochs
[33ma584d6f[m added CUDA, fixed bugs; but still loss is nan
[33m3e2927d[m train.py is running
[33m8beab8a[m remove lua
[33m8d9e41c[m train and dataset stuff working
[33m286a8cb[m train code close to done
[33ma3a01ed[m Merge pull request #20 from y0ast/master
[33mb87368e[m add python2 compatibility, use dataloader, explicit train and eval call on model, general clean up
[33m1174146[m implement VAE
[33m45bd1a9[m checkpoint before DataParallel
[33m7b205ef[m Got preprocess.py working, and some of train.py
[33m3bd3fb3[m initial checkin
[33mc88ba0a[m Fixes to ImageNet training script (#19)
[33md2acdb9[m Merge pull request #18 from pytorch/mnistcleanup
[33m031392f[m cleanup mnist
[33m4d7c05c[m remove tqdm deps
[33m259bf81[m Merge pull request #17 from szagoruyko/patch-1
[33me58713d[m Correct total batch num in dcgan
[33m5a31116[m Merge pull request #16 from colesbury/imagenet
[33m8a19c60[m Update ImageNet training code
[33m12e213c[m __call__ to forward
[33m4ba9ae6[m Merge pull request #15 from MaximumEntropy/master
[33meb23ef1[m Fixed bug with models apart from LSTMs
[33m427eb4d[m removing redundant transforms now
[33m1c19060[m fix for API changes
[33m99a4c64[m fixing dcgan commandline
[33m4c93238[m fixing inference to use volatile variables
[33mcf9c232[m fix data parallel and change checkpointing in dcgan
[33m4e1783a[m Update README.md
[33mec21b20[m Merge pull request #11 from pytorch/dcgan
[33m6937fce[m dcgan
[33m5c32625[m fixed mnist
[33mf346e59[m removing redundant section
[33m27e2a46[m cleaning up imagenet example and making it depend on torchvision
[33m02fc032[m adding target_transform to imagenet dataset
[33m4f2a9b1[m fixes for optim API
[33m067fef5[m Merge pull request #8 from ngimel/resnet_fixes
[33m80aee30[m cast croppint args to ints, fix bottleneck params
[33m8b6c141[m Merge pull request #7 from adamlerer/rnn_generate
[33md15ec95[m Add README and generate.py script
[33m0324719[m doc
[33m3cee95e[m Merge pull request #5 from colesbury/setattr
[33mc0079d1[m Merge pull request #4 from adamlerer/rnn
[33me66247a[m remove rnn namespace
[33m5de71ea[m Assign child modules via attributes
[33m23ac4e3[m Switch to torch rnn, using cudnn
[33mbd4d385[m minor
[33mb9e7c4f[m Fixed comments, and fixed discrepancies to match torch perplexity
[33m2d47f3f[m Add multiple layers to RNN
[33mc456de8[m add PTB dataset
[33m6fde116[m initial commit of word language model
[33m764ac3b[m Remove numpy dependency
[33me7342bb[m fixing APU
[33m3601ea5[m fix mnist example for master
[33mc6def7d[m working resnet training
[33mf0ff86e[m some more bugfixes for imagenet example
[33m9cb71ab[m fix mnist example
[33m093926a[m python 2.7 fixes
[33mbaa4fd2[m ImageNet example
[33mf1d9dbc[m Merge pull request #3 from clementfarabet/master
[33m960518e[m Making CUDA optional for MNIST example
[33m30cea27[m Merge pull request #1 from adamlerer/mnist
[33m77a6ec7[m fix mnist example
[33m8aee60c[m Update example
[33mdbb6542[m Fixes for 2.7
[33m19ee7bb[m adding readme for mnist
[33m7188625[m add readme
[33m3de8643[m python 2.7 compatibility
[33m23933fc[m Add MNIST example
